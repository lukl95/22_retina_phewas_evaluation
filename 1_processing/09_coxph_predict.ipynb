{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "from lifelines.utils import CensoringType\n",
    "from lifelines.utils import concordance_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sc-projects/sc-proj-ukb-cvd\n",
      "experiment path: /sc-projects/sc-proj-ukb-cvd/results/projects/22_retina_phewas/data/230426\n"
     ]
    }
   ],
   "source": [
    "node = !hostname\n",
    "if \"sc\" in node[0]:\n",
    "    base_path = \"/sc-projects/sc-proj-ukb-cvd\"\n",
    "else: \n",
    "    base_path = \"/data/analysis/ag-reils/ag-reils-shared/cardioRS\"\n",
    "print(base_path)\n",
    "\n",
    "project_label = \"22_retina_phewas\"\n",
    "project_path = f\"{base_path}/results/projects/{project_label}\"\n",
    "figure_path = f\"{project_path}/figures\"\n",
    "output_path = f\"{project_path}/data\"\n",
    "\n",
    "pathlib.Path(figure_path).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "experiment = '230426'\n",
    "experiment_path = f\"{output_path}/{experiment}\"\n",
    "print('experiment path:', experiment_path)\n",
    "pathlib.Path(experiment_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "name_dict = {\n",
    "#     \"predictions_cropratio0.3\": \"ConvNextSmall(Retina)+MLP_cropratio0.3\",\n",
    "#     \"predictions_cropratio0.5\": \"ConvNextSmall(Retina)+MLP_cropratio0.5\",\n",
    "#    \"predictions_cropratio0.66\": \"ConvNextSmall(Retina)+MLP_cropratio0.66\",\n",
    "    \"predictions\": \"ConvNextSmall(Retina)+MLP_cropratio0.66\",\n",
    "}\n",
    "\n",
    "#partitions = [i for i in range(22)]\n",
    "partitions = [4, 5, 7, 9, 10, 20] # Partitions with eye test centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today = '230426'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = f\"{experiment_path}/coxph/models\"\n",
    "model_list =  !ls $model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "endpoints = sorted([l.replace('_prevalent', '') for l in list(pd.read_csv(f'/sc-projects/sc-proj-ukb-cvd/results/projects/{project_label}/data/{today}/endpoints.csv').endpoint.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits = [\"train\", \"valid\", 'test'] # \"test_left\", 'test_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_defs = pd.read_feather(f\"{output_path}/phecode_defs_220306.feather\").query(\"endpoint==@endpoints\").sort_values(\"endpoint\").set_index(\"endpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = str(date.today()) if today is None else today\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eligable_eids = pd.read_feather(f\"{output_path}/eligable_eids_{today}.feather\")\n",
    "eids_dict = eligable_eids.set_index(\"endpoint\")[\"eid_list\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_NUM_THREADS=4\n",
      "env: NUMEXPR_NUM_THREADS=4\n",
      "env: OMP_NUM_THREADS=4\n"
     ]
    }
   ],
   "source": [
    "%env MKL_NUM_THREADS=4\n",
    "%env NUMEXPR_NUM_THREADS=4\n",
    "%env OMP_NUM_THREADS=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.9.7', ray_version='1.12.1', ray_commit='4863e33856b54ccf8add5cbe75e41558850a1b75', address_info={'node_ip_address': '10.32.105.1', 'raylet_ip_address': '10.32.105.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-06-05_16-29-31_494340_1505255/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-06-05_16-29-31_494340_1505255/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2023-06-05_16-29-31_494340_1505255', 'metrics_export_port': 58812, 'gcs_address': '10.32.105.1:53939', 'address': '10.32.105.1:53939', 'node_id': '0d438641db5a5cd0c220896cb3e6ed9a33f8e679e216bfe16d16e388'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "#ray.shutdown()\n",
    "#ray start --head --port=6379 --num-cpus 64\n",
    "#ray.init(address='auto')\n",
    "ray.init(num_cpus=16)#, dashboard_port=24762, dashboard_host=\"0.0.0.0\", include_dashboard=True)#, webui_url=\"0.0.0.0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict COX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_path = pathlib.Path(f\"{experiment_path}/coxph/input\")\n",
    "model_path = f\"{experiment_path}/coxph/models\"\n",
    "\n",
    "out_path = f\"{experiment_path}/coxph/predictions\"\n",
    "pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/sc-projects/sc-proj-ukb-cvd/results/projects/22_retina_phewas/data/230426/coxph/input')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ImageTraining_[]_ConvNeXt_MLPHead_predictions']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [f.name for f in in_path.iterdir() if f.is_dir() and \"ipynb_checkpoints\" not in str(f)]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#AgeSex = [\"age_at_recruitment_f21022_0_0\", \"sex_f31_0_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "from lifelines.exceptions import ConvergenceError\n",
    "import zstandard\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def get_score_defs():\n",
    "\n",
    "    with open(r'/sc-projects/sc-proj-ukb-cvd/results/projects/22_retina_phewas/data/score_definitions.yaml') as file:\n",
    "        score_defs = yaml.full_load(file)\n",
    "    \n",
    "    return score_defs\n",
    "\n",
    "def get_features(endpoint, score_defs):\n",
    "    features = {\n",
    "        model: {\n",
    "            \"Age+Sex\": score_defs[\"AgeSex\"],\n",
    "            \"Retina\": [endpoint],\n",
    "            \"SCORE2\": score_defs[\"SCORE2\"],\n",
    "            \"ASCVD\": score_defs[\"ASCVD\"],\n",
    "            \"QRISK3\": score_defs[\"QRISK3\"],\n",
    "            \"Age+Sex+Retina\": score_defs[\"AgeSex\"] + [endpoint],\n",
    "            \"SCORE2+Retina\": score_defs[\"SCORE2\"] + [endpoint],\n",
    "            \"ASCVD+Retina\": score_defs[\"ASCVD\"] + [endpoint],\n",
    "            \"QRISK3+Retina\": score_defs[\"QRISK3\"] + [endpoint],\n",
    "            }\n",
    "        for model in models}\n",
    "    return features\n",
    "\n",
    "#def get_test_data(in_path, partition, models, mapping):\n",
    "def get_test_data(in_path, partition, models):\n",
    "    data = {model: pd.read_feather(f\"{in_path}/{model}/{partition}/test.feather\").set_index(\"eid\")#.replace(mapping)\n",
    "            for model in models}\n",
    "    return data\n",
    "    #left_data = {model: pd.read_feather(f\"{in_path}/{model}/{partition}/test_left.feather\").set_index(\"eid\").replace(mapping)for model in models}\n",
    "    #right_data = {model: pd.read_feather(f\"{in_path}/{model}/{partition}/test_right.feather\").set_index(\"eid\").replace(mapping)for model in models}\n",
    "    #return (left_data, right_data)\n",
    "            \n",
    "def load_pickle(fp):\n",
    "    with open(fp, \"rb\") as fh:\n",
    "        dctx = zstandard.ZstdDecompressor()\n",
    "        with dctx.stream_reader(fh) as decompressor:\n",
    "            data = pickle.loads(decompressor.read())\n",
    "    return data\n",
    "\n",
    "def predict_cox(cph, data_endpoint, endpoint, feature_set, partition, pred_path, model):\n",
    "    times = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "    time_cols = {t: f\"Ft_{t}\" for t in times}\n",
    "    \n",
    "    if feature_set==\"Age+Sex+MedicalHistory+I(Age*MH)\":\n",
    "        data_endpoint.columns = [c.replace(\"-\", \"\") for c in data_endpoint.columns]\n",
    "    \n",
    "    surv_test = 1-cph.predict_survival_function(data_endpoint, times=times)\n",
    "    temp_pred = data_endpoint.reset_index()[[\"eid\"]].assign(endpoint=endpoint, features=feature_set, partition=partition)\n",
    "    for t, col in time_cols.items(): \n",
    "        temp_pred[col] = surv_test.T[t].to_list()\n",
    "    \n",
    "    temp_pred.to_feather(f\"{out_path}/{endpoint}_{feature_set}_{model}_{partition}.feather\") \n",
    "\n",
    "# for both eyes\n",
    "def predict_cox_both_eyes(cph, data_endpoint_left, data_endpoint_right, endpoint, feature_set, partition, pred_path):\n",
    "    times = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "    time_cols = {t: f\"Ft_{t}\" for t in times}\n",
    "    \n",
    "    if feature_set==\"Age+Sex+MedicalHistory+I(Age*MH)\":\n",
    "        data_endpoint_left.columns = [c.replace(\"-\", \"\") for c in data_endpoint_left.columns]\n",
    "        data_endpoint_right.columns = [c.replace(\"-\", \"\") for c in data_endpoint_right.columns]\n",
    "\n",
    "    # left eye\n",
    "    surv_test_left = 1-cph.predict_survival_function(data_endpoint_left, times=times)\n",
    "    temp_pred_left = data_endpoint_left.reset_index()[[\"eid\"]].assign(endpoint=endpoint, features=feature_set, partition=partition)\n",
    "    for t, col in time_cols.items(): \n",
    "        temp_pred_left[col] = surv_test_left.T[t].to_list()\n",
    "    \n",
    "    temp_pred_left.to_feather(f\"{out_path}/{endpoint}_{feature_set}_{partition}_left.feather\")\n",
    "    \n",
    "    # right eye\n",
    "    surv_test_right = 1-cph.predict_survival_function(data_endpoint_right, times=times)\n",
    "    temp_pred_right = data_endpoint_right.reset_index()[[\"eid\"]].assign(endpoint=endpoint, features=feature_set, partition=partition)\n",
    "    for t, col in time_cols.items(): \n",
    "        temp_pred_right[col] = surv_test_right.T[t].to_list()\n",
    "    \n",
    "    temp_pred_right.to_feather(f\"{out_path}/{endpoint}_{feature_set}_{partition}_right.feather\")\n",
    "    \n",
    "    # mean both eyes\n",
    "    eids = list(surv_test_left.columns.values)\n",
    "    surv_test_mean = pd.concat((surv_test_left, surv_test_right), axis=1)\n",
    "    surv_test_mean.columns = [f'{col}_left' for col in list(surv_test_left.columns.values)] + [f'{col}_right' for col in list(surv_test_right.columns.values)]\n",
    "    for eid in eids:\n",
    "        eid_columns = [col for col in list(surv_test_mean.columns.values) if str(eid) in col]\n",
    "        surv_test_mean[f'{eid}_mean'] = surv_test_mean[eid_columns].mean(axis=1)\n",
    "    surv_test_mean = surv_test_mean[[col for col in list(surv_test_mean.columns.values) if 'mean' in col]].rename(columns={col: col.replace('_mean', '') for col in list(surv_test_mean.columns.values)})\n",
    "    \n",
    "    temp_pred_mean = data_endpoint_left.reset_index()[[\"eid\"]].assign(endpoint=endpoint, features=feature_set, partition=partition)\n",
    "    for t, col in time_cols.items(): \n",
    "        temp_pred_mean[col] = surv_test_mean.T[t].to_list()\n",
    "     \n",
    "    temp_pred_mean.to_feather(f\"{out_path}/{endpoint}_{feature_set}_{partition}_mean.feather\")\n",
    "\n",
    "@ray.remote\n",
    "def predict_endpoint(data_partition, eids_dict, endpoint, partition, models, features, model_path, out_path):\n",
    "    #data_partition_left, data_partition_right = data_partition\n",
    "    eids_incl = eids_dict[endpoint].tolist()\n",
    "    results = []\n",
    "    for model in models:\n",
    "        data_model = data_partition[model]\n",
    "        #data_model_left = data_partition_left[model]\n",
    "        #data_model_right = data_partition_right[model]\n",
    "        for feature_set, covariates in features[model].items():\n",
    "            identifier = f\"{endpoint}_{feature_set}_{model}_{partition}\"\n",
    "            pred_path = f\"{out_path}/{identifier}.feather\"\n",
    "            if not os.path.isfile(pred_path):\n",
    "                try:\n",
    "                    cph = load_pickle(f\"{model_path}/{identifier}.p\")\n",
    "                    data_endpoint = data_model[data_model.index.isin(eids_incl)]\n",
    "                    #data_endpoint_left = data_model_left[data_model_left.index.isin(eids_incl)]\n",
    "                    #data_endpoint_right = data_model_right[data_model_right.index.isin(eids_incl)]\n",
    "                    predict_cox(cph, data_endpoint, endpoint, feature_set, partition, pred_path, model)\n",
    "                    #predict_cox_both_eyes(cph, data_endpoint_left, data_endpoint_right, endpoint, feature_set, partition, pred_path)\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"{identifier} not available\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### TEST ####\n",
    "\n",
    "mapping = {\"sex_f31_0_0\": {\"Female\":0, \"Male\":1}}\n",
    "\n",
    "for partition in tqdm([0]): # in tqdm(partitions) # TODO: CHANGE!\n",
    "    try:\n",
    "        data_partition_left, data_partition_right = get_test_data(in_path, partition, models, mapping)\n",
    "        for endpoint in tqdm(endpoints):\n",
    "            print('NEXT ENDPOINT:',endpoint)\n",
    "            features = get_features(endpoint)\n",
    "            if endpoint not in endpoints_not_overlapping_with_preds: # double check if this works as expected\n",
    "                predict_endpoint((data_partition_left, data_partition_right), eids_dict, endpoint, partition, models, features, model_path, out_path)\n",
    "            else:\n",
    "                print('Ã¼berspringe', endpoint)\n",
    "    except FileNotFoundError:\n",
    "        print('file not found')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ff6f7cc2364d17960a397630cb0b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray object not yet initialised\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec5e9c113334baa92a5193d750563f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44c8f5cf97f424fa04e1bdfeeb3c58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7891176125594c3297685851a8df74f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef4ec752b87464ab9d9b7d775f3dd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7c8f92d3f44aba890de5f9e30fe8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3b91bcac2442e5a3da17b7931c1710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "#mapping = {\"sex_f31_0_0\": {\"Female\":0, \"Male\":1}}\n",
    "score_defs = get_score_defs()\n",
    "\n",
    "ray_eids = ray.put(eids_dict)\n",
    "for partition in tqdm(partitions):\n",
    "    try:\n",
    "        del ray_partition\n",
    "    except:\n",
    "        print(\"Ray object not yet initialised\")\n",
    "    #ray_partition = ray.put(get_test_data(in_path, partition, models, mapping))\n",
    "    ray_partition = ray.put(get_test_data(in_path, partition, models))\n",
    "    progress = []\n",
    "    for endpoint in endpoints:\n",
    "        features = get_features(endpoint, score_defs)\n",
    "        progress.append(predict_endpoint.remote(ray_partition, ray_eids, endpoint, partition, models, features, model_path, out_path))\n",
    "    [ray.get(s) for s in tqdm(progress)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
