{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.feather as feather\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "from lifelines.utils import CensoringType\n",
    "from lifelines.utils import concordance_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import ray\n",
    "# ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sc-projects/sc-proj-ukb-cvd\n",
      "experiment path: /sc-projects/sc-proj-ukb-cvd/results/projects/22_retina_phewas/data/230426\n"
     ]
    }
   ],
   "source": [
    "node = !hostname\n",
    "if \"sc\" in node[0]:\n",
    "    base_path = \"/sc-projects/sc-proj-ukb-cvd\"\n",
    "else: \n",
    "    base_path = \"/data/analysis/ag-reils/ag-reils-shared/cardioRS\"\n",
    "print(base_path)\n",
    "\n",
    "project_label = \"22_retina_phewas\"\n",
    "project_path = f\"{base_path}/results/projects/{project_label}\"\n",
    "figure_path = f\"{project_path}/figures\"\n",
    "output_path = f\"{project_path}/data\"\n",
    "\n",
    "pathlib.Path(figure_path).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "experiment = '230426'\n",
    "experiment_path = f\"{output_path}/{experiment}\"\n",
    "print('experiment path:', experiment_path)\n",
    "pathlib.Path(experiment_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "name_dict = {\n",
    "#     \"predictions_cropratio0.3\": \"ConvNextSmall(Retina)+MLP_cropratio0.3\",\n",
    "#     \"predictions_cropratio0.5\": \"ConvNextSmall(Retina)+MLP_cropratio0.5\",\n",
    "#    \"predictions_cropratio0.66\": \"ConvNextSmall(Retina)+MLP_cropratio0.66\",\n",
    "    \"predictions\": \"ConvNextSmall(Retina)+MLP_cropratio0.66\",\n",
    "}\n",
    "\n",
    "#partitions = [i for i in range(22)]\n",
    "partitions = [4, 5, 7, 9, 10, 20] # Partitions with eye test centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RayContext(dashboard_url=None, python_version='3.9.7', ray_version='1.12.1', ray_commit='4863e33856b54ccf8add5cbe75e41558850a1b75', address_info={'node_ip_address': '10.32.105.11', 'raylet_ip_address': '10.32.105.11', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-05-02_14-30-27_232691_1891519/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-05-02_14-30-27_232691_1891519/sockets/raylet', 'webui_url': None, 'session_dir': '/tmp/ray/session_2023-05-02_14-30-27_232691_1891519', 'metrics_export_port': 48810, 'gcs_address': '10.32.105.11:59919', 'address': '10.32.105.11:59919', 'node_id': '3ad2b544f0211b04d78b5e920153f96732ad4bfb36d2917a753ea6c9'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "# ray start --head --port=6379 --num-cpus 64\n",
    "#ray.init(num_cpus=24, include_dashboard=False)#, dashboard_port=24762, dashboard_host=\"0.0.0.0\", include_dashboard=True)#, webui_url=\"0.0.0.0\"))\n",
    "ray.init(address='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "endpoints = sorted([l.replace('_prevalent', '') for l in list(pd.read_csv('/sc-projects/sc-proj-ukb-cvd/results/projects/22_retinal_risk/data/220602/endpoints.csv').endpoint.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113122"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, os\n",
    "img_root = '/sc-projects/sc-proj-ukb-cvd/data/retina/preprocessed/preprocessed'\n",
    "img_visit = 0\n",
    "img_file_extension = '.png'\n",
    "eids_with_retinapic = [int(fp.split('/')[-1].split('_')[0]) for fp in sorted( glob.glob(os.path.join(img_root, f'*{img_file_extension}' \n",
    "                       if img_file_extension is not None else '*'))) \n",
    "                       if f'_{img_visit}_' in fp]\n",
    "len(eids_with_retinapic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61264"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(eids_with_retinapic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sc-projects/sc-proj-ukb-cvd/results/projects/22_retina_phewas/data/data_covariates_full.feather'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{output_path}/data_covariates_full.feather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_covariates = pd.read_feather(f\"{output_path}/data_covariates_full.feather\").set_index(\"eid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_covariates = data_covariates[['age', 'sex', 'ethnic_background']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success, all required covariates are prepared!\n"
     ]
    }
   ],
   "source": [
    "AgeSex = [\"age\", \"sex\"]\n",
    "\n",
    "SCORE2 = [\n",
    "    \"age\", \n",
    "    \"sex\",\n",
    "    \"smoking_status\", # current smoker\n",
    "    \"systolic_blood_pressure\",\n",
    "    \"cholesterol\",\n",
    "    \"hdl_cholesterol\",\n",
    "\n",
    "] \n",
    "\n",
    "ASCVD = [\n",
    "    \"age\", \n",
    "    \"sex\",\n",
    "    \"ethnic_background\",\n",
    "    \"smoking_status\", # current smoker\n",
    "    \"diabetes\", # diabetes\n",
    "    \"antihypertensives\", \n",
    "    \"systolic_blood_pressure\",\n",
    "    \"cholesterol\",\n",
    "    \"hdl_cholesterol\",\n",
    "] \n",
    "\n",
    "QRISK3 = [\n",
    "    \"age\", \n",
    "    \"sex\",\n",
    "    \"ethnic_background\",\n",
    "    \"smoking_status\", # current smoker\n",
    "    \"bmi\",\n",
    "    \"diabetes1\", # type 1 diabetes\n",
    "    \"diabetes2\", # type 1 diabetes\n",
    "    \"fh_heart_disease\",\n",
    "    \"renal_failure\", \n",
    "    \"atrial_fibrillation\", \n",
    "    \"migraine\",\n",
    "    \"rheumatoid_arthritis\", \n",
    "    \"systemic_lupus_erythematosus\", \n",
    "    \"schizophrenia\", \n",
    "    \"bipolar_disorder\", \n",
    "    \"major_depressive_disorder\", \n",
    "    \"male_erectile_dysfunction\", \n",
    "    \"antihypertensives\", \n",
    "    \"corticosteroids\",\n",
    "    \"psycholeptics\",\n",
    "    \"systolic_blood_pressure\",\n",
    "    \"cholesterol\",\n",
    "    \"hdl_cholesterol\",\n",
    "\n",
    "]\n",
    "\n",
    "# assert, that all variables are available\n",
    "covariates_scores = sorted(list(set(AgeSex + SCORE2 + ASCVD + QRISK3)))\n",
    "if not set(covariates_scores).issubset(data_covariates.columns.to_list()):\n",
    "    print(\"Not all required covariates are prepared!\", list(set(covariates_scores).difference(data_covariates.columns.to_list())))\n",
    "else:\n",
    "    print(\"Success, all required covariates are prepared!\")\n",
    "    data_covariates = data_covariates[covariates_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cont:  ['age', 'bmi', 'cholesterol', 'hdl_cholesterol', 'systolic_blood_pressure']\n",
      "Cat:  ['ethnic_background', 'sex', 'smoking_status']\n",
      "Bool:  ['antihypertensives', 'atrial_fibrillation', 'bipolar_disorder', 'corticosteroids', 'diabetes', 'diabetes1', 'diabetes2', 'fh_heart_disease', 'major_depressive_disorder', 'male_erectile_dysfunction', 'migraine', 'psycholeptics', 'renal_failure', 'rheumatoid_arthritis', 'schizophrenia', 'systemic_lupus_erythematosus']\n"
     ]
    }
   ],
   "source": [
    "variables_cont = data_covariates.select_dtypes(include=[\"int32\", \"float32\", \"float64\"]).columns.to_list()#dtypes.to_frame().rename(columns={0:\"dtype\"}).query(\"dtype!='bool'\")\n",
    "variables_cat = data_covariates.select_dtypes(include=[\"category\"]).columns.to_list()\n",
    "variables_bool = data_covariates.select_dtypes(include=[\"bool\"]).columns.to_list()#dtypes.to_frame().rename(columns={0:\"dtype\"}).query(\"dtype!='bool'\")\n",
    "print(\"Cont: \", variables_cont)\n",
    "print(\"Cat: \", variables_cat)\n",
    "print(\"Bool: \", variables_bool)\n",
    "\n",
    "variables_to_norm = variables_cont + endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_path = pathlib.Path(f\"{experiment_path}/loghs\")\n",
    "in_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = f\"{experiment_path}/coxph/input\"\n",
    "pathlib.Path(out_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/sc-projects/sc-proj-ukb-cvd/results/projects/22_retina_phewas/data/230426/loghs')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sc-projects/sc-proj-ukb-cvd/results/projects/22_retina_phewas/data/230426/coxph/input'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ImageTraining_[]_ConvNeXt_MLPHead_predictions']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [f.name for f in in_path.iterdir() if f.is_dir() and \"ipynb_checkpoints\" not in str(f)]\n",
    "for model in models:\n",
    "    pathlib.Path(os.path.join(out_path, model)).mkdir(parents=True, exist_ok=True)\n",
    "    for p in partitions:\n",
    "        pathlib.Path(os.path.join(out_path, model, str(p))).mkdir(parents=True, exist_ok=True)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import miceforest\n",
    "import pickle\n",
    "import zstandard\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# def find_retina_eid_intersection():\n",
    "#     img_root = '/sc-projects/sc-proj-ukb-cvd/data/retina/preprocessed/preprocessed'\n",
    "#     img_visit = 0\n",
    "#     img_file_extension = '.png'\n",
    "#     eids_with_retinapic = [int(fp.split('/')[-1].split('_')[0]) for fp in sorted( glob.glob(os.path.join(img_root, f'*{img_file_extension}' \n",
    "#                            if img_file_extension is not None else '*'))) \n",
    "#                            if f'_{img_visit}_' in fp]\n",
    "#     len(eids_with_retinapic)\n",
    "    \n",
    "#     d = []\n",
    "#     for endpoint in tqdm(endpoints):\n",
    "#         s = data_outcomes[f'{endpoint}_event'].loc[np.intersect1d(eids_dict[endpoint], eids_with_retinapic)]   # .loc[eids_dict[endpoint]]\n",
    "#         n = s.sum()\n",
    "#         freq = s.mean()\n",
    "#         d.append({\"endpoint\": endpoint, \"eligable\":len(np.intersect1d(eids_dict[endpoint], eids_with_retinapic)), \"n\": n, \"freq\": freq})\n",
    "        \n",
    "#     endpoints_freqs = pd.DataFrame().from_dict(d)\n",
    "#     endpoints_ds = endpoints_freqs.query(\"n>100\").sort_values(\"endpoint\")#.reset_index(drop=True)\n",
    "\n",
    "#     return endpoints_ds # TODO\n",
    "\n",
    "def read_merge_data(fp_in, split, data_covariates):\n",
    "    temp = pd.read_feather(f\"{fp_in}/{split}.feather\").set_index(\"eid\")\n",
    "    if 'split' in temp.columns:\n",
    "        temp.drop('split', axis=1, inplace=True)\n",
    "    temp = temp.merge(data_covariates, left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    return temp   \n",
    "\n",
    "def load_pickle(fp):\n",
    "    with open(fp, \"rb\") as fh:\n",
    "        dctx = zstandard.ZstdDecompressor()\n",
    "        with dctx.stream_reader(fh) as decompressor:\n",
    "            data = pickle.loads(decompressor.read())\n",
    "    return data\n",
    "    \n",
    "def save_pickle(data, data_path):\n",
    "    with open(data_path, \"wb\") as fh:\n",
    "        cctx = zstandard.ZstdCompressor()\n",
    "        with cctx.stream_writer(fh) as compressor:\n",
    "            compressor.write(pickle.dumps(data, protocol=pickle.HIGHEST_PROTOCOL))\n",
    "            \n",
    "def get_variable_schema(data):\n",
    "    \n",
    "    missing = data.columns[data.isna().any()].to_list()\n",
    "    \n",
    "    print('Missing columns:', missing)\n",
    "    \n",
    "    variable_schema = {}\n",
    "    for m in missing:\n",
    "        variable_schema[m] = [x for x in data.columns if x != m]\n",
    "    \n",
    "    return variable_schema\n",
    "\n",
    "def tune_imputer(data):\n",
    "    \n",
    "    variable_schema = get_variable_schema(data)\n",
    "        \n",
    "    kernel = miceforest.ImputationKernel(data,\n",
    "                                         datasets=1,\n",
    "                                         random_state=42)#, train_nonmissing=True)\n",
    "    \n",
    "    best_hps, losses = kernel.tune_parameters(dataset=0, n_jobs=96, optimization_steps=5, verbose=True) # add bootstrrapping! \n",
    "  \n",
    "    return best_hps\n",
    "\n",
    "def get_imputer_hps(data_covariates, model, partition, samples):\n",
    "\n",
    "    fp_in = f\"{in_path}/{model}/{partition}\"\n",
    "    fp_out = f\"{out_path}/{model}\" # fp_out = f\"{out_path}/{model}/\"\n",
    "    \n",
    "    temp = read_merge_data(fp_in, \"train\", data_covariates.sample(samples))\n",
    "    \n",
    "    print(\"tune hps\")\n",
    "    best_hps = tune_imputer(temp)\n",
    "    save_pickle(best_hps, f\"{fp_out}/imputer_best_hps.p\")\n",
    "    \n",
    "    return best_hps\n",
    "\n",
    "def fit_imputer(data, best_hps=None):\n",
    "    \n",
    "    variable_schema = get_variable_schema(data)\n",
    "        \n",
    "    kernel = miceforest.ImputationKernel(data,\n",
    "                                         datasets=1,\n",
    "                                         random_state=42)#, train_nonmissing=True)\n",
    "\n",
    "    # Run the MICE algorithm for 3 iterations\n",
    "    kernel.mice(5, n_jobs=16, \n",
    "                variable_parameters=best_hps,\n",
    "                verbose=True)\n",
    "    \n",
    "    return kernel\n",
    "    \n",
    "@ray.remote\n",
    "def scale_encode_save_feather(partition, split, temp_df, scaler, variables_cont, variables_cat, fp_out):\n",
    "    print(partition, split, f\"scale {split}\")\n",
    "    temp_df[variables_cont] = scaler.transform(temp_df[variables_cont].values)\n",
    "\n",
    "    print(partition, split, f\"onehotencode {split}\")\n",
    "    temp_df = pd.get_dummies(temp_df, columns=variables_cat, prefix=variables_cat)\n",
    "\n",
    "    # save imputed and standardized file\n",
    "    print(partition, split, f\"save {split}\")\n",
    "    temp_df.reset_index(drop=False).to_feather(f\"{fp_out}/{split}.feather\")\n",
    "    \n",
    "\n",
    "def impute_norm_variables(data_covariates, model, partition, variables_cont, variables_cat, samples):\n",
    "\n",
    "    fp_in = f\"{in_path}/{model}/{partition}\"\n",
    "    fp_out = f\"{out_path}/{model}/{partition}\"\n",
    "      \n",
    "    if pathlib.Path(fp_in).is_dir():\n",
    "        if not pathlib.Path(fp_out).is_dir():\n",
    "            pathlib.Path(fp_out).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "    for split in tqdm([\"train\", \"valid\", \"test\"]):\n",
    "        \n",
    "        print(partition, split, \"read and merge data\")\n",
    "        temp = read_merge_data(fp_in, split, data_covariates)\n",
    "        \n",
    "        temp = temp.loc[np.intersect1d(temp.index.values, eids_with_retinapic)]\n",
    "\n",
    "        \n",
    "        if split==\"train\": \n",
    "            # fit and save imputer\n",
    "            print(partition, split, \"fit imputer\")\n",
    "            print(partition, split, \"fit imputer: load hps\")\n",
    "#             best_hps = load_pickle(f\"{out_path}/{model}/imputer_best_hps.p\")\n",
    "            print(partition, split, \"fit imputer: fit imputer\")\n",
    "            print(temp.isna().sum()\n",
    "                 )\n",
    "            imputer = fit_imputer(temp.sample(samples),\n",
    "#                                   best_hps\n",
    "                                 )\n",
    "            print(partition, split, \"fit imputer: save imputer\")\n",
    "            save_pickle(imputer, f\"{fp_out}/imputer.p\")\n",
    "            \n",
    "            # check imputer and log results\n",
    "#             print(partition, split, \"check imputer: plot distributions\")\n",
    "#             print(imputer.plot_imputed_distributions(wspace=0.3,hspace=0.3))\n",
    "            #plt.savefig(f\"{fp_out}/imputed_dists.png\")\n",
    "            \n",
    "        # apply imputer and scaler\n",
    "        print(partition, split, f\"impute {split}\")\n",
    "        \n",
    "        if temp.isna().sum().sum() > 0:\n",
    "            temp = imputer.impute_new_data(new_data=temp, verbose=True).complete_data(0)            \n",
    "            \n",
    "        \n",
    "        if split==\"train\": \n",
    "            \n",
    "            # fit and save standardscaler\n",
    "            print(partition, split, \"fit scaler\")\n",
    "            scaler = StandardScaler(with_mean=True, with_std=True, copy=True).fit(temp[variables_cont].values)\n",
    "            save_pickle(scaler, f\"{fp_out}/scaler.p\")\n",
    "            \n",
    "        scale_encode_save_feather.remote(partition, split, temp, scaler, variables_cont, variables_cat, fp_out)\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only execute once to make sure we have a good set of lightgmb parameters\n",
    "#get_imputer_hps(data_covariates, models[0], partitions[0], variables_to_norm, samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#impute_norm_variables(data_covariates, models[0], partitions[0], variables_to_norm, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def norm_logh_and_extra(data_covariates, variables_cont, variables_cat, samples):\n",
    "    \n",
    "    print(f\"Tune and fit imputation with {samples} samples\")\n",
    "    \n",
    "#     for model in models:\n",
    "        # instead of models[0]\n",
    "#         hps_path = f\"{out_path}/{model}/imputer_best_hps.p\"\n",
    "#         if not pathlib.Path(hps_path).is_file():\n",
    "#             print(f\"No HPs found, estimating new HPs...\")\n",
    "#             get_imputer_hps(data_covariates, model, partitions[0], samples)\n",
    "#         else:\n",
    "#             print(f\"Use {hps_path}\")\n",
    "\n",
    "    progress = []\n",
    "    for model in models:\n",
    "        for partition in tqdm(partitions):\n",
    "            progress.append(impute_norm_variables(data_covariates, \n",
    "                                                  model, partition,\n",
    "                                                  variables_cont, \n",
    "                                                  variables_cat,\n",
    "                                                  samples))\n",
    "    #[ray.get(s) for s in tqdm(progress)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encode_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tune and fit imputation with 15000 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c261e0aea00448c9b53f825ad6249a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e10e7fa1e6642e28d7c2f8a87917a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 train read and merge data\n",
      "4 train fit imputer\n",
      "4 train fit imputer: load hps\n",
      "4 train fit imputer: fit imputer\n",
      "OMOP_4306655                      0\n",
      "phecode_002                       0\n",
      "phecode_002-1                     0\n",
      "phecode_003                       0\n",
      "phecode_004                       0\n",
      "                               ... \n",
      "schizophrenia                     0\n",
      "sex                               0\n",
      "smoking_status                  331\n",
      "systemic_lupus_erythematosus      0\n",
      "systolic_blood_pressure         194\n",
      "Length: 1197, dtype: int64\n",
      "Missing columns: ['bmi', 'cholesterol', 'ethnic_background', 'hdl_cholesterol', 'smoking_status', 'systolic_blood_pressure']\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4 train fit imputer: save imputer\n",
      "4 train impute train\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4 train fit scaler\n",
      "4 valid read and merge data\n",
      "4 valid impute valid\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 4 train scale train\n",
      " | hdl_cholesterol\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 4 train onehotencode train\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 4 train save train\n",
      "\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4 test read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 4 valid scale valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 4 valid onehotencode valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 4 valid save valid\n",
      "4 test impute test\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5f3d3f82494dc9873df957dbf949ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 train read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 4 test scale test\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 4 test onehotencode test\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 4 test save test\n",
      "5 train fit imputer\n",
      "5 train fit imputer: load hps\n",
      "5 train fit imputer: fit imputer\n",
      "OMOP_4306655                      0\n",
      "phecode_002                       0\n",
      "phecode_002-1                     0\n",
      "phecode_003                       0\n",
      "phecode_004                       0\n",
      "                               ... \n",
      "schizophrenia                     0\n",
      "sex                               0\n",
      "smoking_status                  284\n",
      "systemic_lupus_erythematosus      0\n",
      "systolic_blood_pressure          90\n",
      "Length: 1197, dtype: int64\n",
      "Missing columns: ['bmi', 'cholesterol', 'ethnic_background', 'hdl_cholesterol', 'smoking_status', 'systolic_blood_pressure']\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5 train fit imputer: save imputer\n",
      "5 train impute train\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5 train fit scaler\n",
      "5 valid read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 5 train scale train\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 5 train onehotencode train\n",
      "5 valid impute valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 5 train save train\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5 test read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 5 valid scale valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 5 valid onehotencode valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 5 valid save valid\n",
      "5 test impute test\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aafd109d1564726a35e4273cea27ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 train read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 5 test scale test\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 5 test onehotencode test\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 5 test save test\n",
      "7 train fit imputer\n",
      "7 train fit imputer: load hps\n",
      "7 train fit imputer: fit imputer\n",
      "OMOP_4306655                      0\n",
      "phecode_002                       0\n",
      "phecode_002-1                     0\n",
      "phecode_003                       0\n",
      "phecode_004                       0\n",
      "                               ... \n",
      "schizophrenia                     0\n",
      "sex                               0\n",
      "smoking_status                  283\n",
      "systemic_lupus_erythematosus      0\n",
      "systolic_blood_pressure         189\n",
      "Length: 1197, dtype: int64\n",
      "Missing columns: ['bmi', 'cholesterol', 'ethnic_background', 'hdl_cholesterol', 'smoking_status', 'systolic_blood_pressure']\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "7 train fit imputer: save imputer\n",
      "7 train impute train\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "7 train fit scaler\n",
      "7 valid read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 7 train scale train\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 7 train onehotencode train\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 7 train save train\n",
      "7 valid impute valid\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "7 test read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 7 valid scale valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 7 valid onehotencode valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 7 valid save valid\n",
      "7 test impute test\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 7 test scale test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb729d1d04884cf2b266a57234263937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 train read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 7 test onehotencode test\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 7 test save test\n",
      "9 train fit imputer\n",
      "9 train fit imputer: load hps\n",
      "9 train fit imputer: fit imputer\n",
      "OMOP_4306655                      0\n",
      "phecode_002                       0\n",
      "phecode_002-1                     0\n",
      "phecode_003                       0\n",
      "phecode_004                       0\n",
      "                               ... \n",
      "schizophrenia                     0\n",
      "sex                               0\n",
      "smoking_status                  235\n",
      "systemic_lupus_erythematosus      0\n",
      "systolic_blood_pressure         172\n",
      "Length: 1197, dtype: int64\n",
      "Missing columns: ['bmi', 'cholesterol', 'ethnic_background', 'hdl_cholesterol', 'smoking_status', 'systolic_blood_pressure']\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "9 train fit imputer: save imputer\n",
      "9 train impute train\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "9 train fit scaler\n",
      "9 valid read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 9 train scale train\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 9 train onehotencode train\n",
      "9 valid impute valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 9 train save train\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "9 test read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 9 valid scale valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 9 valid onehotencode valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 9 valid save valid\n",
      "9 test impute test\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d94d30bda241e2bb66ad903f0bdacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 train read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 9 test scale test\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 9 test onehotencode test\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 9 test save test\n",
      "10 train fit imputer\n",
      "10 train fit imputer: load hps\n",
      "10 train fit imputer: fit imputer\n",
      "OMOP_4306655                      0\n",
      "phecode_002                       0\n",
      "phecode_002-1                     0\n",
      "phecode_003                       0\n",
      "phecode_004                       0\n",
      "                               ... \n",
      "schizophrenia                     0\n",
      "sex                               0\n",
      "smoking_status                  237\n",
      "systemic_lupus_erythematosus      0\n",
      "systolic_blood_pressure         171\n",
      "Length: 1197, dtype: int64\n",
      "Missing columns: ['bmi', 'cholesterol', 'ethnic_background', 'hdl_cholesterol', 'smoking_status', 'systolic_blood_pressure']\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "10 train fit imputer: save imputer\n",
      "10 train impute train\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "10 train fit scaler\n",
      "10 valid read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 10 train scale train\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 10 train onehotencode train\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 10 train save train\n",
      "10 valid impute valid\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "10 test read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 10 valid scale valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 10 valid onehotencode valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 10 valid save valid\n",
      "10 test impute test\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | smoking_status | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 10 test scale test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f4aa4f6d564d5f8848a0b9435bc192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 train read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 10 test onehotencode test\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 10 test save test\n",
      "20 train fit imputer\n",
      "20 train fit imputer: load hps\n",
      "20 train fit imputer: fit imputer\n",
      "OMOP_4306655                      0\n",
      "phecode_002                       0\n",
      "phecode_002-1                     0\n",
      "phecode_003                       0\n",
      "phecode_004                       0\n",
      "                               ... \n",
      "schizophrenia                     0\n",
      "sex                               0\n",
      "smoking_status                  339\n",
      "systemic_lupus_erythematosus      0\n",
      "systolic_blood_pressure         178\n",
      "Length: 1197, dtype: int64\n",
      "Missing columns: ['bmi', 'cholesterol', 'ethnic_background', 'hdl_cholesterol', 'smoking_status', 'systolic_blood_pressure']\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "20 train fit imputer: save imputer\n",
      "20 train impute train\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "20 train fit scaler\n",
      "20 valid read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 20 train scale train\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 20 train onehotencode train\n",
      "20 valid impute valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 20 train save train\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | smoking_status | ethnic_background | cholesterol | hdl_cholesterol\n",
      "20 test read and merge data\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 20 valid scale valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 20 valid onehotencode valid\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 20 valid save valid\n",
      "20 test impute test\n",
      "Dataset 0\n",
      "1  | systolic_blood_pressure | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "2  | systolic_blood_pressure | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "3  | systolic_blood_pressure | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "4  | systolic_blood_pressure | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "5  | systolic_blood_pressure | bmi | ethnic_background | cholesterol | hdl_cholesterol\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 20 test scale test\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 20 test onehotencode test\n",
      "\u001b[2m\u001b[36m(scale_encode_save_feather pid=1941678)\u001b[0m 20 test save test\n"
     ]
    }
   ],
   "source": [
    "norm_logh_and_extra(data_covariates, variables_cont, variables_cat, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
