{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import subprocess\n",
    "import re\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from tqdm.auto import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONFIG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# USER = 'YOURUSERNAME'\n",
    "# BASE = f'/home/{USER}/RetinalRisk'\n",
    "CODE_BASE = '/sc-projects/sc-proj-ukb-cvd/code/RetinalRisk'\n",
    "SUBMISSION_BASE = '/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk'\n",
    "\n",
    "TAG = 230905\n",
    "JOBNAME = f'fullrun_retina'\n",
    "\n",
    "EXPERIMENT_NAME = f'22_retinalrisk_{TAG}_{JOBNAME}'   # name under which to store the generated .sh scripts and yamls\n",
    "TEMPLATE_CONFIG = f'{CODE_BASE}/config/'   # template yaml to use\n",
    "TRAIN_SCRIPT = f'{CODE_BASE}/retinalrisk/scripts/train_retina.py'     # python train script to use\n",
    "\n",
    "# os.makedirs(f'/home/{USER}/tmp/{EXPERIMENT_NAME}/job_submissions', exist_ok=True)\n",
    "# os.makedirs(f'/home/{USER}/tmp/{EXPERIMENT_NAME}/job_configs', exist_ok=True)\n",
    "\n",
    "os.makedirs(f'{SUBMISSION_BASE}/{EXPERIMENT_NAME}/job_submissions', exist_ok=True)\n",
    "os.makedirs(f'{SUBMISSION_BASE}/{EXPERIMENT_NAME}/job_configs', exist_ok=True)\n",
    "os.makedirs(f'{SUBMISSION_BASE}/{EXPERIMENT_NAME}/job_outputs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_HYPERPARAMS = [\n",
    " f'setup.name={TAG}_{JOBNAME}',\n",
    "    \"training.gradient_checkpointing=False\",\n",
    "    \"training.patience=40\",\n",
    "    \"datamodule/covariates=no_covariates\",\n",
    "    \"model=image\",\n",
    "    \"setup.use_data_artifact_if_available=False\",\n",
    "    \"head=mlp\",\n",
    "    \"head.kwargs.num_hidden=512\",\n",
    "    \"head.kwargs.num_layers=2\",\n",
    "    \"head.dropout=0.5\",\n",
    "    \"training.optimizer_kwargs.weight_decay=0.001\",\n",
    "    \"training.optimizer_kwargs.lr=0.0001\",\n",
    "    \"model.freeze_encoder=False\",\n",
    "    \"model.encoder=convnext_small\",\n",
    "    \"datamodule.batch_size=256\",\n",
    "    \"training.warmup_period=8\",\n",
    "    \"datamodule/augmentation=contrast_sharpness_posterize\",\n",
    "    \"datamodule.img_size_to_gpu=420\",\n",
    "    \"datamodule.num_workers=16\",\n",
    "    \"model.pretrained=True\",\n",
    " ]\n",
    "\n",
    "RETAGESEX_HYPERPARAMS = [\n",
    " f'setup.name={TAG}_RetAgeSex',\n",
    "    'training.gradient_checkpointing=False', \n",
    "    'training.patience=40', \n",
    "    'datamodule/covariates=agesex', \n",
    "    'model=image', \n",
    "    'setup.use_data_artifact_if_available=False', \n",
    "    'head=mlp', \n",
    "    'head.kwargs.num_hidden=512', \n",
    "    'head.kwargs.num_layers=2', \n",
    "    'head.dropout=0.5', \n",
    "    'training.optimizer_kwargs.weight_decay=0.001', \n",
    "    'training.optimizer_kwargs.lr=0.0001', \n",
    "    'model.freeze_encoder=False', \n",
    "    'model.encoder=convnext_small', \n",
    "    'datamodule.batch_size=256', \n",
    "    'training.warmup_period=8', \n",
    "    'datamodule/augmentation=contrast_sharpness_posterize', \n",
    "    'datamodule.img_size_to_gpu=420',\n",
    "    'datamodule.num_workers=16',\n",
    "    'model.pretrained=True',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'datamodule.partition': [0, 4, 5, 7, 9, 10, 20], # Partitions with eye test centers\n",
    "    # partition 0 should have no samples and should fail, included as a sanity check\n",
    "    #'datamodule.partition': [i for i in range(0, 5)], # CHRISTINA\n",
    "    #'datamodule.partition': [i for i in range(5, 10)], # PAUL \n",
    "    #'datamodule.partition': [i for i in range(10, 16)], # THORE \n",
    "    #'datamodule.partition': [i for i in range(16, 22)], # LUKAS \n",
    "}\n",
    "\n",
    "parameters_retagesex = {\n",
    "    'datamodule.partition': [20], # only with best partition\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_job_script(job_name, base_params, hyperparams):\n",
    "    \n",
    "    params_str = ' '.join(base_params + hyperparams)\n",
    "\n",
    "    job_script_str = f'''#!/bin/bash\n",
    "#SBATCH --job-name={job_name}                # Specify job name\n",
    "#SBATCH --partition=gpu                     # Specify partition name\n",
    "#SBATCH --nodes=1-1                          # Specify number of nodes\n",
    "#SBATCH --cpus-per-gpu=62\n",
    "#SBATCH --mem=400GB                          # Use entire memory of node\n",
    "#SBATCH --gres=gpu:nvidia_a100_80gb_pcie:1   # Generic resources; 1 80GB GPU\n",
    "#SBATCH --time=48:00:00                      # Set a limit on the total run time\n",
    "#SBATCH --error={SUBMISSION_BASE}/{EXPERIMENT_NAME}/job_outputs/slurm-%A_%a.err\n",
    "#SBATCH --output={SUBMISSION_BASE}/{EXPERIMENT_NAME}/job_outputs/slurm-%A_%a.out\n",
    "\n",
    "\n",
    "source ~/miniconda3/etc/profile.d/conda.sh\n",
    "conda activate /sc-projects/sc-proj-ukb-cvd/environments/retina\n",
    "\n",
    "python {TRAIN_SCRIPT} --config-path {TEMPLATE_CONFIG} ''' + params_str\n",
    "    \n",
    "    return job_script_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submit(path, job_name, job_script, time_stamp=None):\n",
    "    if not time_stamp:\n",
    "        time_stamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        \n",
    "    script_path_long = f'{path}/{job_name}_{time_stamp}.sh'\n",
    "\n",
    "    with open(script_path_long, 'w') as outfile: \n",
    "        outfile.write(job_script)\n",
    "    script_path = f'{path}/{job_name}.sh'\n",
    "    try:\n",
    "        os.unlink(script_path)\n",
    "    except FileNotFoundError: # because we cannot overwrite symlinks directly\n",
    "        pass\n",
    "    os.symlink(os.path.realpath(script_path_long), script_path)\n",
    "\n",
    "    print('\\n\\nSubmission:\\n===========\\n')\n",
    "    sub_cmd = f'sbatch < {script_path}'\n",
    "    print(sub_cmd)\n",
    "    \n",
    "    ret = subprocess.run(sub_cmd, shell=True, cwd=os.getcwd(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "#     print(ret.stdout.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN RETINA + AGE + SEX Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=fullrun_retina                # Specify job name\n",
      "#SBATCH --partition=gpu                     # Specify partition name\n",
      "#SBATCH --nodes=1-1                          # Specify number of nodes\n",
      "#SBATCH --cpus-per-gpu=62\n",
      "#SBATCH --mem=400GB                          # Use entire memory of node\n",
      "#SBATCH --gres=gpu:nvidia_a100_80gb_pcie:1   # Generic resources; 1 80GB GPU\n",
      "#SBATCH --time=48:00:00                      # Set a limit on the total run time\n",
      "#SBATCH --error=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.err\n",
      "#SBATCH --output=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.out\n",
      "\n",
      "\n",
      "source ~/miniconda3/etc/profile.d/conda.sh\n",
      "conda activate /sc-projects/sc-proj-ukb-cvd/environments/retina\n",
      "\n",
      "python /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/retinalrisk/scripts/train_retina.py --config-path /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/config/ setup.name=230905_RetAgeSex training.gradient_checkpointing=False training.patience=40 datamodule/covariates=agesex model=image setup.use_data_artifact_if_available=False head=mlp head.kwargs.num_hidden=512 head.kwargs.num_layers=2 head.dropout=0.5 training.optimizer_kwargs.weight_decay=0.001 training.optimizer_kwargs.lr=0.0001 model.freeze_encoder=False model.encoder=convnext_small datamodule.batch_size=256 training.warmup_period=8 datamodule/augmentation=contrast_sharpness_posterize datamodule.img_size_to_gpu=420 datamodule.num_workers=16 model.pretrained=True datamodule.partition=20\n",
      "\n",
      "\n",
      "Submission:\n",
      "===========\n",
      "\n",
      "sbatch < /sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_submissions/fullrun_retina_0.sh\n"
     ]
    }
   ],
   "source": [
    "for i, hp_vals in enumerate(itertools.product(*parameters_retagesex.values(), repeat=1)):\n",
    "    hyperparams = [f\"{p}={v}\" for p, v in zip(parameters.keys(), hp_vals)]\n",
    "    job_script = make_job_script(#user=USER,\n",
    "                                 job_name=JOBNAME,\n",
    "                                 base_params=RETAGESEX_HYPERPARAMS,\n",
    "                                 hyperparams=hyperparams)\n",
    "    print(job_script)\n",
    "\n",
    "    # jobid = submit(path=f\"/home/{USER}/tmp/{EXPERIMENT_NAME}/job_submissions\",\n",
    "    jobid = submit(path=f\"{SUBMISSION_BASE}/{EXPERIMENT_NAME}/job_submissions\",\n",
    "                   job_name=JOBNAME+f'_{i}',\n",
    "                   job_script=job_script)\n",
    "\n",
    "    jobids.append(jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN RETINA TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "#SBATCH --job-name=fullrun_retina                # Specify job name\n",
      "#SBATCH --partition=gpu                     # Specify partition name\n",
      "#SBATCH --nodes=1-1                          # Specify number of nodes\n",
      "#SBATCH --cpus-per-gpu=62\n",
      "#SBATCH --mem=400GB                          # Use entire memory of node\n",
      "#SBATCH --gres=gpu:nvidia_a100_80gb_pcie:1   # Generic resources; 1 80GB GPU\n",
      "#SBATCH --time=50:00:00                      # Set a limit on the total run time\n",
      "#SBATCH --error=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.err\n",
      "#SBATCH --output=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.out\n",
      "\n",
      "\n",
      "source ~/miniconda3/etc/profile.d/conda.sh\n",
      "conda activate /sc-projects/sc-proj-ukb-cvd/environments/retina\n",
      "\n",
      "python /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/retinalrisk/scripts/train_retina.py --config-path /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/config/ setup.name=230905_fullrun_retina training.gradient_checkpointing=False training.patience=40 datamodule/covariates=no_covariates model=image setup.use_data_artifact_if_available=False head=mlp head.kwargs.num_hidden=512 head.kwargs.num_layers=2 head.dropout=0.5 training.optimizer_kwargs.weight_decay=0.001 training.optimizer_kwargs.lr=0.0001 model.freeze_encoder=False model.encoder=convnext_small datamodule.batch_size=256 training.warmup_period=8 datamodule/augmentation=contrast_sharpness_posterize datamodule.img_size_to_gpu=420 datamodule.num_workers=16 model.pretrained=True datamodule.partition=0\n",
      "\n",
      "\n",
      "Submission:\n",
      "===========\n",
      "\n",
      "sbatch < /sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_submissions/fullrun_retina_0.sh\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=fullrun_retina                # Specify job name\n",
      "#SBATCH --partition=gpu                     # Specify partition name\n",
      "#SBATCH --nodes=1-1                          # Specify number of nodes\n",
      "#SBATCH --cpus-per-gpu=62\n",
      "#SBATCH --mem=400GB                          # Use entire memory of node\n",
      "#SBATCH --gres=gpu:nvidia_a100_80gb_pcie:1   # Generic resources; 1 80GB GPU\n",
      "#SBATCH --time=50:00:00                      # Set a limit on the total run time\n",
      "#SBATCH --error=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.err\n",
      "#SBATCH --output=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.out\n",
      "\n",
      "\n",
      "source ~/miniconda3/etc/profile.d/conda.sh\n",
      "conda activate /sc-projects/sc-proj-ukb-cvd/environments/retina\n",
      "\n",
      "python /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/retinalrisk/scripts/train_retina.py --config-path /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/config/ setup.name=230905_fullrun_retina training.gradient_checkpointing=False training.patience=40 datamodule/covariates=no_covariates model=image setup.use_data_artifact_if_available=False head=mlp head.kwargs.num_hidden=512 head.kwargs.num_layers=2 head.dropout=0.5 training.optimizer_kwargs.weight_decay=0.001 training.optimizer_kwargs.lr=0.0001 model.freeze_encoder=False model.encoder=convnext_small datamodule.batch_size=256 training.warmup_period=8 datamodule/augmentation=contrast_sharpness_posterize datamodule.img_size_to_gpu=420 datamodule.num_workers=16 model.pretrained=True datamodule.partition=4\n",
      "\n",
      "\n",
      "Submission:\n",
      "===========\n",
      "\n",
      "sbatch < /sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_submissions/fullrun_retina_1.sh\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=fullrun_retina                # Specify job name\n",
      "#SBATCH --partition=gpu                     # Specify partition name\n",
      "#SBATCH --nodes=1-1                          # Specify number of nodes\n",
      "#SBATCH --cpus-per-gpu=62\n",
      "#SBATCH --mem=400GB                          # Use entire memory of node\n",
      "#SBATCH --gres=gpu:nvidia_a100_80gb_pcie:1   # Generic resources; 1 80GB GPU\n",
      "#SBATCH --time=50:00:00                      # Set a limit on the total run time\n",
      "#SBATCH --error=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.err\n",
      "#SBATCH --output=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.out\n",
      "\n",
      "\n",
      "source ~/miniconda3/etc/profile.d/conda.sh\n",
      "conda activate /sc-projects/sc-proj-ukb-cvd/environments/retina\n",
      "\n",
      "python /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/retinalrisk/scripts/train_retina.py --config-path /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/config/ setup.name=230905_fullrun_retina training.gradient_checkpointing=False training.patience=40 datamodule/covariates=no_covariates model=image setup.use_data_artifact_if_available=False head=mlp head.kwargs.num_hidden=512 head.kwargs.num_layers=2 head.dropout=0.5 training.optimizer_kwargs.weight_decay=0.001 training.optimizer_kwargs.lr=0.0001 model.freeze_encoder=False model.encoder=convnext_small datamodule.batch_size=256 training.warmup_period=8 datamodule/augmentation=contrast_sharpness_posterize datamodule.img_size_to_gpu=420 datamodule.num_workers=16 model.pretrained=True datamodule.partition=5\n",
      "\n",
      "\n",
      "Submission:\n",
      "===========\n",
      "\n",
      "sbatch < /sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_submissions/fullrun_retina_2.sh\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=fullrun_retina                # Specify job name\n",
      "#SBATCH --partition=gpu                     # Specify partition name\n",
      "#SBATCH --nodes=1-1                          # Specify number of nodes\n",
      "#SBATCH --cpus-per-gpu=62\n",
      "#SBATCH --mem=400GB                          # Use entire memory of node\n",
      "#SBATCH --gres=gpu:nvidia_a100_80gb_pcie:1   # Generic resources; 1 80GB GPU\n",
      "#SBATCH --time=50:00:00                      # Set a limit on the total run time\n",
      "#SBATCH --error=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.err\n",
      "#SBATCH --output=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.out\n",
      "\n",
      "\n",
      "source ~/miniconda3/etc/profile.d/conda.sh\n",
      "conda activate /sc-projects/sc-proj-ukb-cvd/environments/retina\n",
      "\n",
      "python /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/retinalrisk/scripts/train_retina.py --config-path /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/config/ setup.name=230905_fullrun_retina training.gradient_checkpointing=False training.patience=40 datamodule/covariates=no_covariates model=image setup.use_data_artifact_if_available=False head=mlp head.kwargs.num_hidden=512 head.kwargs.num_layers=2 head.dropout=0.5 training.optimizer_kwargs.weight_decay=0.001 training.optimizer_kwargs.lr=0.0001 model.freeze_encoder=False model.encoder=convnext_small datamodule.batch_size=256 training.warmup_period=8 datamodule/augmentation=contrast_sharpness_posterize datamodule.img_size_to_gpu=420 datamodule.num_workers=16 model.pretrained=True datamodule.partition=7\n",
      "\n",
      "\n",
      "Submission:\n",
      "===========\n",
      "\n",
      "sbatch < /sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_submissions/fullrun_retina_3.sh\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=fullrun_retina                # Specify job name\n",
      "#SBATCH --partition=gpu                     # Specify partition name\n",
      "#SBATCH --nodes=1-1                          # Specify number of nodes\n",
      "#SBATCH --cpus-per-gpu=62\n",
      "#SBATCH --mem=400GB                          # Use entire memory of node\n",
      "#SBATCH --gres=gpu:nvidia_a100_80gb_pcie:1   # Generic resources; 1 80GB GPU\n",
      "#SBATCH --time=50:00:00                      # Set a limit on the total run time\n",
      "#SBATCH --error=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.err\n",
      "#SBATCH --output=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.out\n",
      "\n",
      "\n",
      "source ~/miniconda3/etc/profile.d/conda.sh\n",
      "conda activate /sc-projects/sc-proj-ukb-cvd/environments/retina\n",
      "\n",
      "python /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/retinalrisk/scripts/train_retina.py --config-path /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/config/ setup.name=230905_fullrun_retina training.gradient_checkpointing=False training.patience=40 datamodule/covariates=no_covariates model=image setup.use_data_artifact_if_available=False head=mlp head.kwargs.num_hidden=512 head.kwargs.num_layers=2 head.dropout=0.5 training.optimizer_kwargs.weight_decay=0.001 training.optimizer_kwargs.lr=0.0001 model.freeze_encoder=False model.encoder=convnext_small datamodule.batch_size=256 training.warmup_period=8 datamodule/augmentation=contrast_sharpness_posterize datamodule.img_size_to_gpu=420 datamodule.num_workers=16 model.pretrained=True datamodule.partition=9\n",
      "\n",
      "\n",
      "Submission:\n",
      "===========\n",
      "\n",
      "sbatch < /sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_submissions/fullrun_retina_4.sh\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=fullrun_retina                # Specify job name\n",
      "#SBATCH --partition=gpu                     # Specify partition name\n",
      "#SBATCH --nodes=1-1                          # Specify number of nodes\n",
      "#SBATCH --cpus-per-gpu=62\n",
      "#SBATCH --mem=400GB                          # Use entire memory of node\n",
      "#SBATCH --gres=gpu:nvidia_a100_80gb_pcie:1   # Generic resources; 1 80GB GPU\n",
      "#SBATCH --time=50:00:00                      # Set a limit on the total run time\n",
      "#SBATCH --error=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.err\n",
      "#SBATCH --output=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.out\n",
      "\n",
      "\n",
      "source ~/miniconda3/etc/profile.d/conda.sh\n",
      "conda activate /sc-projects/sc-proj-ukb-cvd/environments/retina\n",
      "\n",
      "python /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/retinalrisk/scripts/train_retina.py --config-path /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/config/ setup.name=230905_fullrun_retina training.gradient_checkpointing=False training.patience=40 datamodule/covariates=no_covariates model=image setup.use_data_artifact_if_available=False head=mlp head.kwargs.num_hidden=512 head.kwargs.num_layers=2 head.dropout=0.5 training.optimizer_kwargs.weight_decay=0.001 training.optimizer_kwargs.lr=0.0001 model.freeze_encoder=False model.encoder=convnext_small datamodule.batch_size=256 training.warmup_period=8 datamodule/augmentation=contrast_sharpness_posterize datamodule.img_size_to_gpu=420 datamodule.num_workers=16 model.pretrained=True datamodule.partition=10\n",
      "\n",
      "\n",
      "Submission:\n",
      "===========\n",
      "\n",
      "sbatch < /sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_submissions/fullrun_retina_5.sh\n",
      "#!/bin/bash\n",
      "#SBATCH --job-name=fullrun_retina                # Specify job name\n",
      "#SBATCH --partition=gpu                     # Specify partition name\n",
      "#SBATCH --nodes=1-1                          # Specify number of nodes\n",
      "#SBATCH --cpus-per-gpu=62\n",
      "#SBATCH --mem=400GB                          # Use entire memory of node\n",
      "#SBATCH --gres=gpu:nvidia_a100_80gb_pcie:1   # Generic resources; 1 80GB GPU\n",
      "#SBATCH --time=50:00:00                      # Set a limit on the total run time\n",
      "#SBATCH --error=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.err\n",
      "#SBATCH --output=/sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_outputs/slurm-%A_%a.out\n",
      "\n",
      "\n",
      "source ~/miniconda3/etc/profile.d/conda.sh\n",
      "conda activate /sc-projects/sc-proj-ukb-cvd/environments/retina\n",
      "\n",
      "python /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/retinalrisk/scripts/train_retina.py --config-path /sc-projects/sc-proj-ukb-cvd/code/RetinalRisk/config/ setup.name=230905_fullrun_retina training.gradient_checkpointing=False training.patience=40 datamodule/covariates=no_covariates model=image setup.use_data_artifact_if_available=False head=mlp head.kwargs.num_hidden=512 head.kwargs.num_layers=2 head.dropout=0.5 training.optimizer_kwargs.weight_decay=0.001 training.optimizer_kwargs.lr=0.0001 model.freeze_encoder=False model.encoder=convnext_small datamodule.batch_size=256 training.warmup_period=8 datamodule/augmentation=contrast_sharpness_posterize datamodule.img_size_to_gpu=420 datamodule.num_workers=16 model.pretrained=True datamodule.partition=20\n",
      "\n",
      "\n",
      "Submission:\n",
      "===========\n",
      "\n",
      "sbatch < /sc-projects/sc-proj-ukb-cvd/submissions/RetinalRisk/22_retinalrisk_230905_fullrun_retina/job_submissions/fullrun_retina_6.sh\n"
     ]
    }
   ],
   "source": [
    "for i, hp_vals in enumerate(itertools.product(*parameters.values(), repeat=1)):\n",
    "    hyperparams = [f\"{p}={v}\" for p, v in zip(parameters.keys(), hp_vals)]\n",
    "    job_script = make_job_script(#user=USER,\n",
    "                                 job_name=JOBNAME,\n",
    "                                 base_params=BASE_HYPERPARAMS,\n",
    "                                 hyperparams=hyperparams)\n",
    "    print(job_script)\n",
    "\n",
    "    # jobid = submit(path=f\"/home/{USER}/tmp/{EXPERIMENT_NAME}/job_submissions\",\n",
    "    jobid = submit(path=f\"{SUBMISSION_BASE}/{EXPERIMENT_NAME}/job_submissions\",\n",
    "                   job_name=JOBNAME+f'_{i}',\n",
    "                   job_script=job_script)\n",
    "\n",
    "    jobids.append(jobid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T13:58:38.218338Z",
     "iopub.status.busy": "2022-06-03T13:58:38.218191Z",
     "iopub.status.idle": "2022-06-03T13:58:38.221923Z",
     "shell.execute_reply": "2022-06-03T13:58:38.221498Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.218319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "print(jobids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUSFÃœHRUNG BIS HIER REICHT, DANKE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-03T13:58:38.222818Z",
     "iopub.status.busy": "2022-06-03T13:58:38.222531Z",
     "iopub.status.idle": "2022-06-03T13:58:38.235928Z",
     "shell.execute_reply": "2022-06-03T13:58:38.234922Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.222801Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (244539343.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_772231/244539343.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    @@ halt.\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "@@ halt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.236838Z",
     "iopub.status.idle": "2022-06-03T13:58:38.237057Z",
     "shell.execute_reply": "2022-06-03T13:58:38.236958Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.236947Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.237617Z",
     "iopub.status.idle": "2022-06-03T13:58:38.237782Z",
     "shell.execute_reply": "2022-06-03T13:58:38.237705Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.237695Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.238388Z",
     "iopub.status.idle": "2022-06-03T13:58:38.238554Z",
     "shell.execute_reply": "2022-06-03T13:58:38.238470Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.238461Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ehrgraphs.data.datamodules import EHRGraphDataModule\n",
    "from ehrgraphs.training import setup_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.239206Z",
     "iopub.status.idle": "2022-06-03T13:58:38.239375Z",
     "shell.execute_reply": "2022-06-03T13:58:38.239296Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.239287Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs(path=\"cardiors/RecordGraphs\", filters={\"display_name\": \"220420_t0_ablation\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.240062Z",
     "iopub.status.idle": "2022-06-03T13:58:38.240229Z",
     "shell.execute_reply": "2022-06-03T13:58:38.240150Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.240141Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for r in runs:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.240793Z",
     "iopub.status.idle": "2022-06-03T13:58:38.240957Z",
     "shell.execute_reply": "2022-06-03T13:58:38.240872Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.240864Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "run_df = pd.DataFrame(\n",
    "    [\n",
    "        dict(\n",
    "            run_id=r.id,\n",
    "            buffer_years=eval(r.config[\"_content\"][\"datamodule\"])[\"t0_mode\"],\n",
    "            val_mean_cindex=r.summary[\"valid/mean_CIndex_max\"],\n",
    "        )\n",
    "        for r in runs if r.state == 'finished'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.241594Z",
     "iopub.status.idle": "2022-06-03T13:58:38.241753Z",
     "shell.execute_reply": "2022-06-03T13:58:38.241677Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.241668Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.242443Z",
     "iopub.status.idle": "2022-06-03T13:58:38.242596Z",
     "shell.execute_reply": "2022-06-03T13:58:38.242519Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.242511Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = run_df.copy()\n",
    "tmp = tmp.sort_values('val_mean_cindex', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.243179Z",
     "iopub.status.idle": "2022-06-03T13:58:38.243335Z",
     "shell.execute_reply": "2022-06-03T13:58:38.243260Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.243251Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.243915Z",
     "iopub.status.idle": "2022-06-03T13:58:38.244076Z",
     "shell.execute_reply": "2022-06-03T13:58:38.243995Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.243987Z"
    }
   },
   "outputs": [],
   "source": [
    "order = tmp['buffer_years'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.244640Z",
     "iopub.status.idle": "2022-06-03T13:58:38.244795Z",
     "shell.execute_reply": "2022-06-03T13:58:38.244720Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.244711Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp['cat'] = pd.Categorical(tmp['buffer_years'], categories=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.245374Z",
     "iopub.status.idle": "2022-06-03T13:58:38.245529Z",
     "shell.execute_reply": "2022-06-03T13:58:38.245451Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.245442Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-03T13:58:38.246269Z",
     "iopub.status.idle": "2022-06-03T13:58:38.246427Z",
     "shell.execute_reply": "2022-06-03T13:58:38.246352Z",
     "shell.execute_reply.started": "2022-06-03T13:58:38.246343Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(ggplot() \n",
    " + geom_point(\n",
    "     tmp,\n",
    "     aes(x='val_mean_cindex', y='cat',\n",
    "         fill='val_mean_cindex',\n",
    "         color='val_mean_cindex'\n",
    "        ),\n",
    " )\n",
    " + theme(figure_size=(5, 5))\n",
    "#  + scale_fill_brewer(type='qual', palette=3)\n",
    "#  + scale_color_brewer(type='qual', palette=3)\n",
    " + theme_classic()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "vscode": {
   "interpreter": {
    "hash": "5272fbec9bcbd772c2ec24579ad7573dc515f5a0dbbf2ff5072e16f39c825da9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
